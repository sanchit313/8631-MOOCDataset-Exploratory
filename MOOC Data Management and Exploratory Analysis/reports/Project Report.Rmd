---
title: "Project Report for Data Exploration and Analysis of MOOC Dataset"
author: "Sanchit Bhatnagar"
date: "03/12/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
```
library(ProjectTemplate)
load.project()

## R Markdown

##BUSINESS OBJECTIVES

We will be analysing a fast growing business application area called Learning
Analytics. It is an application for Data Science, defined as “the measurement, 
collection, analysis and reporting of data about learners and their contexts, 
for purposes of understanding and optimizing learning and the environment in which it occurs”.

In the existing scenario of recording student presence through their attendance,
student's engagement outside of the classroom as in their
home, libraries,Virtual viewing etc is not reflected. The objective of the 
Learning Analytics organization is to analyse more student Data based on 
various sources through which they access course work.

Several different Sources of data are periodically collected about the 
organizations learners like their use of on-campus facilities, Virtual Learning 
Environment (VLE) and ReCap access, and student wellbeing referrals.

The main objective of our organization 'Learning Analytics' is to aggregate 
all the important sources of data to derive insights, provide the impactful
measures of engagement.

From analysing the above, there is scope of getting extremely useful information
like:
-how to better the design of learning
-inform intervention processes for at-risk students
-improving student attainment.

The Success Criteria is the efficient access of data from all the
sources without any loss, discrepancy, damage and quality of the student's data.
Also, gathering the maximum data possible in all situations.

For the entire task, we need to efficiently explore, analyse, assess, interpret,
judge and find insights from the datasets that have been provided to us.


#RESOURCES AVAILABLE
We have been supplied with Data for the Cyber security course from future learn 
course. Given Datasets of 7 batches of students, which enrolled in 
a cyber security Future Learn course available online. The data covers various types of information
such as:
-The enrollments of students with student specific ID and the dates of enrolling and leaving
-The types of students (by background), their surveys
-The various countries from which students attended the course
-The Video statistics based on the number of views of the available videos, 
number of downloads, region wise viewing, percentage of completion etc.
-Dates of completing different steps from the online course.

There is another set of data that displays the user interface of the course.
It is same for all 7 cohorts and shows us the all the steps that cover the whole 
course with a step number and one-line description, that enrolled students require
to complete.

##RESOURCES REQUIRED

For our end of the analysis, we require following available resources:
1. A computer/laptop with R installed
2. Software Tools: Rstudio with all the required packages and libraries.
3. An official GIT hub account for acting as our project's repository.
4. The Datasets in appropriate format (eg. csv files).
5. The Interface summarizing the videos



##ASSUMPTIONS

We will make a set of assumptions based on our Application area and its
Datasets as summarized below:

1. The visual display of the interface for the cyber security course is totally
same as the actual one and it shows all of the steps that are required for 
course completion accurately.

2. The Steps of the course are consistent throughout for all the 7 cohorts

3. Some of the data sets are completely blank, we will assume that they fall under
incomplete information provided, hence, can be discarded.

4. We are assuming that all of the information is accurate, with minumum discrepancy 
and gathered from reliable resources.

##RISKS AND CONTINGENCIES

Due to safety purposes, we pre-define possible risks :

1. The data provided to us is from 2016 to 2018, there is a possibility of 
it not being reliable based on the analysis we will carry out on it that will be used for future
improvement of the course.

2.Technological risks such as file corruption, data deletion, power outage and entire computer corruption

3.Data quality can be extremely poor and render unreliable, the name of the files determine the sequence number of the cohort but the data within the files could be mismatched.


##DATA MINING OBJECTIVE
The data we have been given is in its raw form. We are supposed to analyse and interpret it to find useful information from it. Our main objectives of data mining from the given sets are:

*Determine the number of enrollments in each cohorts and compare them with each other to get the basic idea of the average enrollments in a particular batch.

*To find out the number of enrollments across each cohort for every country, this will help us determine the popular places where our course is in demand and we would need to allocate more resources and bandwidth for those places, as well as, focusing more on advertisements and publicizing in the places with higher potential of clients.

*The files containing video statistics help us to find the correlation between the types of videos that each cohort watches the most, with their length of duration, total number of views and their downloads, can determine what if there is a relation among those variables, that can be used for analysis further to classify types of videos, make improvements, alter the length of duration, improve downloading methods. 

*The Video statistics file consists of the information of the percentage of views across various devices, namely: console,	desktop,	mobile,	television,	tablet,	unknown devices. 
We will use this data to determine the most widely used device, the least used device and if any devices faced issues, hence, planning our future courses to have more compatibility in certain devices and access to more devices if required.


##PROJECT PLAN

### An initial project plan is laid out as follows:

-We will use Data analysis and documentation tools in our systems to first select the required data sheets, successfully load them and then perform exploratory analysis on them using R. It will be feasibly carried out using different R packages for reproducibility and also by using a code repository on several different systems.

*We need to determine the number of enrollments across all of the 7 cohorts and get a basic estimate of the number,the number of enrollments across every country whose citizens have enrolled in it, draw inferences from the video statistics on what video is most played, downloaded etc and the various devices used for playing the videos.
The above tasks will be performed using data analysis in R using several Packages for this purpose like plyr,countrycode,forcats,testthat,ggpubr, tidyverse,ggplot2 etc.

*Our 40 percent of the time and effort is expected for Data Preparation Phase and 30 percent for the Data Understanding Phase,25 percent in each of the Modeling, Evaluation, and Business Understanding Phases and 5 percent in the the Deployment Phase.

*Our decision will be based on the graphs and plots that we generate for our tasks and the mean and correlations between various video sets will provide us with analytical information to build decisions.

*We need to constantly update our code repository (we are using GIT hub for this) after updating any files or codes in our project.


#TECHNOLOGIES USED

###We will work on the following technologies based on our requirements:

####1)Microsoft Excel 
It is best for when the first time we receive the data, we can get the sense of how much of data is provided to us and what is it basically about. The files we have been provided are in .csv format, for which Excel does a really great job in separating into columns and rows.

###2)R
R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. For our proper analysis of the data, a tool for stats and graphics will be best suited for us, also its convenient syntax, fast computations, several in-built functions will be supportive throughout our analysis.

###3)Rstudio
After having R in our system, we can use a good IDE (Integrated development environment) where R can be used even more efficiently and conveniently. Rstudio provides a wide number of benefits like
making it easy to write scripts,set a directory and use files on the system, access objects more easily and graphics are easily accessible for a non technical person.

###4)



```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
